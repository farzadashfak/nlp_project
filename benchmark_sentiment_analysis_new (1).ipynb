{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e8720d00",
      "metadata": {
        "id": "e8720d00"
      },
      "source": [
        "# Sentiment Analysis Benchmarking\n",
        "\n",
        "Benchmark three sentiment analysis approaches:\n",
        "1. Rule-based: VADER\n",
        "2. Traditional ML: TF-IDF + Logistic Regression\n",
        "3. Deep Learning SOTA: RoBERTa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73fbd95f",
      "metadata": {
        "id": "73fbd95f",
        "outputId": "13325bd2-3484-4a5d-8b1f-a1454b906ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    import random\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7780e7d",
      "metadata": {
        "id": "d7780e7d",
        "outputId": "01ab5180-7763-4c12-a316-646f1f991cc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 10001 SST rows and 931 review rows; total 10,932 examples.\n"
          ]
        }
      ],
      "source": [
        "reviews_df = pd.read_csv('./Reviews.csv')\n",
        "sst_df = pd.read_csv(\n",
        "    './training.1600000.processed.noemoticon.csv',\n",
        "    names=['target','ids','date','flag','user','text'],\n",
        "    encoding='latin-1'\n",
        ")\n",
        "\n",
        "sst_df = sst_df[sst_df.target.isin([0,4])].copy()\n",
        "sst_df['sentiment'] = sst_df.target.map({0: 'negative', 4: 'positive'})\n",
        "\n",
        "reviews_df = reviews_df[['Score','Text']].dropna()\n",
        "reviews_df['sentiment'] = (\n",
        "    reviews_df.Score\n",
        "      .apply(lambda x: 'positive' if x > 3 else ('negative' if x < 3 else 'neutral'))\n",
        ")\n",
        "reviews_df = reviews_df[reviews_df.sentiment != 'neutral']\n",
        "\n",
        "n_samples = 20000\n",
        "n_sst = len(sst_df)\n",
        "n_rev = len(reviews_df)\n",
        "n_sst_sample = min(n_samples, n_sst)\n",
        "n_rev_sample = min(n_samples, n_rev)\n",
        "\n",
        "sst_sample = sst_df[['text','sentiment']].sample(\n",
        "    n=n_sst_sample, random_state=42\n",
        ")\n",
        "reviews_sample = (\n",
        "    reviews_df[['Text','sentiment']]\n",
        "      .rename(columns={'Text':'text'})\n",
        "      .sample(n=n_rev_sample, random_state=42)\n",
        ")\n",
        "\n",
        "data = pd.concat([sst_sample, reviews_sample], ignore_index=True)\n",
        "X = data.text.values\n",
        "y = data.sentiment.values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Using {n_sst_sample} SST rows and {n_rev_sample} review rows; \"\n",
        "      f\"total {len(data):,} examples.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40f83c5",
      "metadata": {
        "id": "c40f83c5"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()\n",
        "\n",
        "def vader_predict(texts):\n",
        "    preds = []\n",
        "    for t in texts:\n",
        "        score = sid.polarity_scores(t)['compound']\n",
        "        preds.append('positive' if score >= 0 else 'negative')\n",
        "    return preds\n",
        "\n",
        "vader_preds = vader_predict(X_test)\n",
        "print(\"VADER Accuracy:\", accuracy_score(y_test, vader_preds))\n",
        "print(classification_report(y_test, vader_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "103c11a6",
      "metadata": {
        "id": "103c11a6"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "ml_preds = clf.predict(X_test_tfidf)\n",
        "\n",
        "print(\"ML Accuracy:\", accuracy_score(y_test, ml_preds))\n",
        "print(classification_report(y_test, ml_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb0578a",
      "metadata": {
        "id": "bbb0578a"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
        "    use_fast=True\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        ")\n",
        "\n",
        "roberta = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "def roberta_predict(texts, batch_size=32):\n",
        "    preds = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        # ensure it's a Python list of strings\n",
        "        if not isinstance(batch, list):\n",
        "            batch = batch.tolist()\n",
        "\n",
        "        # enforce truncation & padding\n",
        "        results = roberta(\n",
        "            batch,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=512,\n",
        "        )\n",
        "        preds += [\n",
        "            \"positive\" if r[\"label\"].lower().startswith(\"positive\") else \"negative\"\n",
        "            for r in results\n",
        "        ]\n",
        "    return preds\n",
        "\n",
        "X_test_list = X_test.tolist() if hasattr(X_test, \"tolist\") else list(X_test)\n",
        "roberta_preds = roberta_predict(X_test_list)\n",
        "\n",
        "print(\"RoBERTa Accuracy:\", accuracy_score(y_test, roberta_preds))\n",
        "print(classification_report(y_test, roberta_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8fa4634",
      "metadata": {
        "id": "b8fa4634"
      },
      "outputs": [],
      "source": [
        "methods = ['VADER', 'TF-IDF+LR', 'RoBERTa']\n",
        "scores = [\n",
        "    accuracy_score(y_test, vader_preds),\n",
        "    accuracy_score(y_test, ml_preds),\n",
        "    accuracy_score(y_test, roberta_preds)\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.bar(methods, scores)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Sentiment Analysis Benchmark')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJKIx6xtYtOB"
      },
      "id": "yJKIx6xtYtOB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "ORw2gKJTEpiI"
      },
      "id": "ORw2gKJTEpiI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2DLmrK53FuOJ"
      },
      "id": "2DLmrK53FuOJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\", use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "0mR9jkCbGpH-"
      },
      "id": "0mR9jkCbGpH-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare the data frame to convert to hugging face dataset\n",
        "train_df = pd.DataFrame({\n",
        "    'text': X_train,\n",
        "    'label': [1 if x == 'positive' else 0 for x in y_train]\n",
        "})\n",
        "test_df = pd.DataFrame({\n",
        "    'text': X_test,\n",
        "    'label': [1 if x == 'positive' else 0 for x in y_test]\n",
        "})\n",
        "\n",
        "# convert to a hugging face dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n"
      ],
      "metadata": {
        "id": "zKZtxpvuG4PZ"
      },
      "id": "zKZtxpvuG4PZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./roberta_finetuned_sentiment\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    save_total_limit=1,\n",
        "    report_to=\"none\",\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# fine tuning the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "0Bp3nMOoHOdd"
      },
      "id": "0Bp3nMOoHOdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./roberta_finetuned_sentiment\")\n",
        "tokenizer.save_pretrained(\"./roberta_finetuned_sentiment\")\n"
      ],
      "metadata": {
        "id": "kORIO927JumB"
      },
      "id": "kORIO927JumB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# Loading the new finetuned model we just trained\n",
        "finetuned_model_path = \"./roberta_finetuned_sentiment\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(finetuned_model_path)\n",
        "\n",
        "finetuned_pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=128\n",
        ")\n"
      ],
      "metadata": {
        "id": "kywvdcFpJ_sE"
      },
      "id": "kywvdcFpJ_sE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_list = X_test.tolist() if hasattr(X_test, \"tolist\") else list(X_test)\n",
        "\n",
        "finetuned_preds_raw = finetuned_pipeline(X_test_list, batch_size=32)\n"
      ],
      "metadata": {
        "id": "iSi0j1TZKA39"
      },
      "id": "iSi0j1TZKA39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_preds = [\n",
        "    \"negative\" if pred[\"label\"] == \"LABEL_0\" else \"positive\"\n",
        "    for pred in finetuned_preds_raw\n",
        "]\n"
      ],
      "metadata": {
        "id": "eo7bLOJKKIif"
      },
      "id": "eo7bLOJKKIif",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "fine_tuned_roberta_acc = accuracy_score(y_test, finetuned_preds)\n",
        "\n",
        "print(\"Fine-tuned RoBERTa Accuracy:\", fine_tuned_roberta_acc)\n",
        "print(classification_report(y_test, finetuned_preds))\n"
      ],
      "metadata": {
        "id": "isZ8IbrXKLZQ"
      },
      "id": "isZ8IbrXKLZQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "methods = ['VADER', 'TF-IDF+LR', 'Pretrained RoBERTa', 'Fine-tuned RoBERTa']\n",
        "scores = [\n",
        "    accuracy_score(y_test, vader_preds),\n",
        "    accuracy_score(y_test, ml_preds),\n",
        "    accuracy_score(y_test, roberta_preds),\n",
        "    fine_tuned_roberta_acc\n",
        "]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "bars = plt.bar(methods, scores)\n",
        "bars[-1].set_color('red')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Sentiment Analysis Benchmark')\n",
        "plt.ylim(0, 1)\n",
        "for index, value in enumerate(scores):\n",
        "    plt.text(index, value + 0.02, f\"{value:.2f}\", ha='center')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8pNPxYpCKNun"
      },
      "id": "8pNPxYpCKNun",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}